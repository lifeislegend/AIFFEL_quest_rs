{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f74dae",
   "metadata": {},
   "source": [
    "# MAIN QUEST 01 Transformer GPT-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6d915",
   "metadata": {},
   "source": [
    "# Transformer vs. GPT-1 ë³€ê²½ì  ìš”ì•½\n",
    "\n",
    "ê¸°ì¡´ Transformer ëª¨ë¸ê³¼ GPT-1 ëª¨ë¸ì˜ ì£¼ìš” ì°¨ì´ì  ë° ì½”ë“œ ìˆ˜ì • ë°©í–¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1.  **ì•„í‚¤í…ì²˜:**\n",
    "    * Transformer: Encoder-Decoder êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ë²ˆì—­ê³¼ ê°™ì€ Sequence-to-Sequence ì‘ì—…ì— ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    * GPT-1: Decoder-only êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤. ì£¼ë¡œ ì–¸ì–´ ëª¨ë¸ë§ ë° ìƒì„± ì‘ì—…ì— íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "    * **ìˆ˜ì •:** ì œê³µëœ ì½”ë“œëŠ” ì´ë¯¸ `gpt` í•¨ìˆ˜ ë‚´ì—ì„œ Decoder êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì–´, ì•„í‚¤í…ì²˜ì˜ í° ë³€ê²½ì€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë°ì´í„° ì…ë ¥ íŒŒì´í”„ë¼ì¸ì´ Seq2Seq í˜•íƒœ(input/target ìŒ)ê°€ ì•„ë‹Œ, ì–¸ì–´ ëª¨ë¸ë§ í˜•íƒœ(ë‹¤ìŒ í† í° ì˜ˆì¸¡)ë¡œ ìˆ˜ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "2.  **ì…ë ¥ ì²˜ë¦¬:**\n",
    "    * Transformer: Encoder ì…ë ¥ê³¼ Decoder ì…ë ¥ (Teacher Forcing ì‹œ ì´ì „ íƒ€ê²Ÿ ì‹œí€€ìŠ¤)ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "    * GPT-1 (Pre-training): ì—°ì†ëœ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ë§ ëª©í‘œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    * **ìˆ˜ì •:** ê¸°ì¡´ ì½”ë“œëŠ” ì§ˆë¬¸(Q)ê³¼ ë‹µë³€(A)ì„ ë³„ë„ë¡œ í† í°í™”í•˜ê³ , `inputs`ì™€ `dec_inputs`ë¥¼ ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤. GPT-1 ì–¸ì–´ ëª¨ë¸ í•™ìŠµì„ ìœ„í•´, ë°ì´í„°ë¥¼ ë‹¨ì¼ ì‹œí€€ìŠ¤ë¡œ ì²˜ë¦¬í•˜ê³ , ì…ë ¥ ì‹œí€€ìŠ¤ (`inputs`)ì™€ íƒ€ê²Ÿ ì‹œí€€ìŠ¤ (`outputs`, ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ í•œ ì¹¸ ë¯¼ ê²ƒ)ë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "3.  **Attention Mask:**\n",
    "    * Transformer: Encoder Self-Attention, Decoder Masked Self-Attention, Encoder-Decoder Attention ì‚¬ìš©.\n",
    "    * GPT-1: Masked Self-Attention (Look-ahead Mask)ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    * **ìˆ˜ì •:** ì œê³µëœ ì½”ë“œì˜ `create_look_ahead_mask` í•¨ìˆ˜ì™€ `MultiHeadAttention` ë‚´ ë§ˆìŠ¤í¬ ì ìš© ë¡œì§ì€ GPT-1 ë°©ì‹ê³¼ í˜¸í™˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "4.  **Position Encoding:**\n",
    "    * Transformer (Original): Sinusoidal (sine and cosine) ë°©ì‹ ì‚¬ìš©.\n",
    "    * GPT-1: í•™ìŠµ ê°€ëŠ¥í•œ Wording Embedding and Position Embedding ì‚¬ìš©. \n",
    "    * **ìˆ˜ì •:** ì œê³µëœ ì½”ë“œëŠ” ì´ë¯¸ í•™ìŠµ ê°€ëŠ¥í•œ Position Embedding (`tf.keras.layers.Embedding`)ì„ ì‚¬ìš©í•˜ê³  ìˆì–´, ìˆ˜ì •ì´ í•„ìš” ì—†ìŒ. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ, word embeddingë„ ê°™ì´ ì‚¬ìš©. ë”°ë¼ì„œ, í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜ í›„ ì„ë² ë”©, ë‹¨ì–´ ìœ„ì¹˜ ì •ë³´ë¥¼ í•™ìŠµ ê°€ëŠ¥í•œ ë²¡í„°ë¡œ ë³€í™˜, ë‹¨ì–´ì˜ë¯¸ + ìœ„ì¹˜ì •ë³´ë¥¼ ë”í•˜ì—¬ ìµœì¢… ì…ë ¥ ë²¡í„° ìƒì„±.\n",
    "\n",
    "5.  **Feed-Forward Network Activation:**\n",
    "    * Transformer (Original): ReLU ì‚¬ìš©.\n",
    "    * GPT-1: GELU (Gaussian Error Linear Unit) ì‚¬ìš©.\n",
    "    * **ìˆ˜ì •:** `decoder_layer` ë‚´ì˜ Dense ë ˆì´ì–´ í™œì„±í™” í•¨ìˆ˜ë¥¼ ReLUì—ì„œ GELUë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "6.  **ë°ì´í„°ì…‹ êµ¬ì„± ë° í•™ìŠµ:**\n",
    "    * **ìˆ˜ì •:** `tf.data.Dataset` ìƒì„± ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬, ëª¨ë¸ì´ ì˜ˆìƒí•˜ëŠ” ì…ë ¥ í˜•íƒœ (`inputs`)ì™€ íƒ€ê²Ÿ (`outputs`)ì„ ì˜¬ë°”ë¥´ê²Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬ ì½”ë“œì˜ ë°ì´í„°ì…‹ êµ¬ì¡°ëŠ” `ValueError: Missing data for input \"input_1\"` ì˜¤ë¥˜ì˜ ì›ì¸ì…ë‹ˆë‹¤. ì´ë¥¼ ì–¸ì–´ ëª¨ë¸ë§ì— ë§ê²Œ `(ì…ë ¥ ì‹œí€€ìŠ¤, íƒ€ê²Ÿ ì‹œí€€ìŠ¤)` íŠœí”Œ í˜•íƒœë¡œ ìˆ˜ì •í•©ë‹ˆë‹¤. (ì²˜ìŒì— ë°œìƒí•œ ì˜¤ë¥˜ ë¶€ë¶„ ìˆ˜ì •) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b54a7caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# MAIN QUEST 01 Transformer GPT-1 (ì½”ë“œ ì‹œì‘)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ ì¶”ê°€\n",
    "import tensorflow_datasets as tfds # í† í¬ë‚˜ì´ì €ë¥¼ ìœ„í•´ ì¶”ê°€\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538dc11c",
   "metadata": {},
   "source": [
    "## Step 1. Data Loads & Preprocessing & Utilize SubwordTextEncoder\n",
    "\n",
    "1. ë°ì´í„° ë¡œë“œ\n",
    "í•œêµ­ì–´ ì±—ë´‡ ë°ì´í„°ëŠ” ì†¡ì˜ìˆ™ë‹˜ì´ ê³µê°œí•œ ì±—ë´‡ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë°ì´í„°ëŠ” ì•„ë˜ì˜ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
    "\n",
    "Cloud shellì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "ğ‘šğ‘˜ğ‘‘ğ‘–ğ‘Ÿâˆ’ğ‘ /ğ‘ğ‘–ğ‘“ğ‘“ğ‘’ğ‘™/ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘ ğ‘“ğ‘œğ‘Ÿğ‘šğ‘’ğ‘Ÿğ‘â„ğ‘ğ‘¡ğ‘ğ‘œğ‘¡/ğ‘‘ğ‘ğ‘¡ğ‘/\n",
    "ln -s ~/data/* ~/aiffel/transformer_chatbot/data/\n",
    "\n",
    "2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "ì˜ì–´ ë°ì´í„°ì™€ëŠ” ì „í˜€ ë‹¤ë¥¸ ë°ì´í„°ì¸ ë§Œí¼ ì˜ì–´ ë°ì´í„°ì— ì‚¬ìš©í–ˆë˜ ì „ì²˜ë¦¬ì™€ ì¼ë¶€ ë™ì¼í•œ ì „ì²˜ë¦¬ë„ í•„ìš”í•˜ê² ì§€ë§Œ \n",
    "ì „ì²´ì ìœ¼ë¡œëŠ” ë‹¤ë¥¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "3. ë‹¨ì–´ í† í°í™” ê³¼ì • \n",
    "í•œêµ­ì–´ ë°ì´í„°ëŠ” í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í¬ë‚˜ì´ì§•ì„ í•´ì•¼ í•œë‹¤ê³  ë§ì€ ë¶„ì´ ì•Œê³  ìˆìŠµë‹ˆë‹¤.\n",
    "í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ ì•„ë‹Œ ìœ„ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í–ˆë˜ \n",
    "ë‚´ë¶€ ë‹¨ì–´ í† í¬ë‚˜ì´ì €ì¸ SubwordTextEncoderë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c38bbe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì§ˆë¬¸ ìˆ˜: 11823\n",
      "ì´ ë‹µë³€ ìˆ˜: 11823\n",
      "ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ ì§ˆë¬¸: 12ì‹œ ë•¡ !\n",
      "ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ ë‹µë³€: í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš” .\n",
      "START_TOKEN: [8168]\n",
      "END_TOKEN: [8169]\n",
      "VOCAB_SIZE: 8170\n",
      "Tokenized questions shape: (11823, 40)\n",
      "Dataset Input shape: (64, 39)\n",
      "Dataset Target shape: (64, 39)\n",
      "Sample Input: tf.Tensor(\n",
      "[8168 2078   80  541  148 3475 8169    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0], shape=(39,), dtype=int32)\n",
      "Sample Target: tf.Tensor(\n",
      "[2078   80  541  148 3475 8169    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0], shape=(39,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# ì±—ë´‡ ë°ì´í„° ë¡œë“œ\n",
    "path = os.getenv('HOME') + '/aiffel/songys_chatbot/ChatbotData.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# ì „ì²˜ë¦¬ í•¨ìˆ˜ (ë™ì¼)\n",
    "def preprocess_sentence(sentence):\n",
    "    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # í•œêµ­ì–´, ì˜ì–´, ìˆ«ì, ì£¼ìš” êµ¬ë‘ì , ê³µë°± ì™¸ ì œê±° (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)\n",
    "    sentence = re.sub(r\"[^ê°€-í£ã„±-ã…ã…-ã…£a-zA-Z?.!,1-9\\s]\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "# ì§ˆë¬¸, ë‹µë³€ ë¶ˆëŸ¬ì˜¤ê¸° (ë™ì¼)\n",
    "def load_conversations():\n",
    "    inputs, outputs = [], []\n",
    "    for idx, row in data.iterrows():\n",
    "        q = row['Q']\n",
    "        a = row['A']\n",
    "        # ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì´ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ê±´ë„ˆë›°ê¸° (ë°ì´í„° ì˜¤ë¥˜ ë°©ì§€)\n",
    "        if isinstance(q, str) and isinstance(a, str):\n",
    "            inputs.append(preprocess_sentence(q))\n",
    "            outputs.append(preprocess_sentence(a))\n",
    "        elif isinstance(q, str): # ë‹µë³€ì´ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš° ì§ˆë¬¸ë§Œ ì‚¬ìš©\n",
    "             inputs.append(preprocess_sentence(q))\n",
    "        elif isinstance(a, str): # ì§ˆë¬¸ì´ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš° ë‹µë³€ë§Œ ì‚¬ìš© (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ì§€ë§Œ ì•ˆì „í•˜ê²Œ)\n",
    "             outputs.append(preprocess_sentence(a))\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "questions, answers = load_conversations()\n",
    "print(f\"ì´ ì§ˆë¬¸ ìˆ˜: {len(questions)}\")\n",
    "print(f\"ì´ ë‹µë³€ ìˆ˜: {len(answers)}\")\n",
    "print(\"ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ ì§ˆë¬¸:\", questions[0])\n",
    "print(\"ì „ì²˜ë¦¬ í›„ ìƒ˜í”Œ ë‹µë³€:\", answers[0])\n",
    "\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¹Œë“œ (ì§ˆë¬¸ê³¼ ë‹µë³€ ëª¨ë‘ ì‚¬ìš©)\n",
    "# SubwordTextEncoder\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "print(f\"START_TOKEN: {START_TOKEN}\")\n",
    "print(f\"END_TOKEN: {END_TOKEN}\")\n",
    "print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
    "\n",
    "\n",
    "# ìµœëŒ€ ë¬¸ì¥ ê¸¸ì´ (ë™ì¼)\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "# ì •ìˆ˜ ì¸ì½”ë”© + íŒ¨ë”© (ì§ˆë¬¸ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •)\n",
    "# í•¨ìˆ˜ ì´ë¦„ì€ ìœ ì§€í•˜ë˜, ë‚´ë¶€ ë¡œì§ ë³€ê²½ (GPT ì–¸ì–´ ëª¨ë¸ë§ì— ë§ê²Œ ì§ˆë¬¸ë§Œ ì²˜ë¦¬)\n",
    "def tokenize_and_filter(inputs):\n",
    "    tokenized_inputs = []\n",
    "    for sentence in inputs:\n",
    "        # ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í° ì¶”ê°€\n",
    "        sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN\n",
    "        # ìµœëŒ€ ê¸¸ì´ ì´í•˜ì¸ ê²½ìš°ë§Œ listì— ì¶”ê°€\n",
    "        if len(sentence) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence)\n",
    "\n",
    "    # íŒ¨ë”© ì²˜ë¦¬\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "# ì§ˆë¬¸ ë°ì´í„°ë§Œ í† í°í™” ë° í•„í„°ë§\n",
    "questions_tokenized = tokenize_and_filter(questions)\n",
    "print(\"Tokenized questions shape:\", questions_tokenized.shape)\n",
    "\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¤€ë¹„ (GPT ì–¸ì–´ ëª¨ë¸ë§ ë°©ì‹)\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000 # ë°ì´í„°ê°€ ì‘ìœ¼ë¯€ë¡œ BUFFER_SIZE ì¡°ì • ê°€ëŠ¥\n",
    "\n",
    "# ì…ë ¥: questions_tokenizedì˜ ë§ˆì§€ë§‰ í† í° ì œì™¸ [:, :-1]\n",
    "# íƒ€ê²Ÿ: questions_tokenizedì˜ ì²« í† í° ì œì™¸ [:, 1:]\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    questions_tokenized[:, :-1], # ì…ë ¥ ì‹œí€€ìŠ¤\n",
    "    questions_tokenized[:, 1:]  # íƒ€ê²Ÿ ì‹œí€€ìŠ¤ (ì…ë ¥ì„ í•œ ìŠ¤í… ë¯¼ ê²ƒ)\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸ (í•˜ë‚˜ì˜ ë°°ì¹˜ ìƒ˜í”Œ ì¶œë ¥)\n",
    "for inputs, targets in dataset.take(1):\n",
    "    print(\"Dataset Input shape:\", inputs.shape)      # (BATCH_SIZE, MAX_LENGTH - 1)\n",
    "    print(\"Dataset Target shape:\", targets.shape)    # (BATCH_SIZE, MAX_LENGTH - 1)\n",
    "    print(\"Sample Input:\", inputs[0])\n",
    "    print(\"Sample Target:\", targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55213f7",
   "metadata": {},
   "source": [
    "*ëª©ì°¨*\n",
    "1. Padding Mask\n",
    "2. Look Ahead Masking\n",
    "3. Multi Head Attention\n",
    "4. Decoding Layer & Decoder\n",
    "5. GPT Model define (word embedding + positional embedding)\n",
    "ìœ„ ì‹¤ìŠµ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a1ddd",
   "metadata": {},
   "source": [
    "## Step 2. Masking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c78947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x) # ì…ë ¥ ìì²´ì— ëŒ€í•œ íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231611ee",
   "metadata": {},
   "source": [
    "## Step 3. Multi-Head Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7fff1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % num_heads == 0\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(d_model)\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        scaled_attention = tf.matmul(attention_weights, value)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        output = self.dense(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248f5d2",
   "metadata": {},
   "source": [
    "## Step 4. Decoder Layer (GPT-1)\n",
    "reference: Radford, A., & Narasimhan, K. (2018). Improving Language Understanding by Generative Pre-Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a46f09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Decoder Layer ìˆ˜ì • (name ì¸ì ì¶”ê°€)\n",
    "def decoder_layer(units, d_model, num_heads, dropout_rate, name=\"decoder_layer\"): # name ì¸ì ì¶”ê°€\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"layer_inputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"layer_look_ahead_mask\")\n",
    "\n",
    "    # Masked Multi-Head Self-Attention (ì²« ë²ˆì§¸ ì„œë¸Œì¸µ)\n",
    "    # MultiHeadAttention ë ˆì´ì–´ ì´ë¦„ë„ ê³ ìœ í•˜ê²Œ ì„¤ì • (ì„ íƒ ì‚¬í•­)\n",
    "    attention_layer = MultiHeadAttention(d_model, num_heads) # ì´ë¦„ ì¤‘ë³µ í”¼í•˜ê¸° ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    attention = attention_layer(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask # Look-ahead mask ì ìš©\n",
    "    })\n",
    "    attention = tf.keras.layers.Dropout(dropout_rate)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs) # Add & Norm\n",
    "\n",
    "    # Position-wise Feed-Forward Network (ë‘ ë²ˆì§¸ ì„œë¸Œì¸µ)\n",
    "    # í™œì„±í™” í•¨ìˆ˜ë¥¼ 'relu' -> 'gelu'ë¡œ ë³€ê²½\n",
    "    outputs = tf.keras.layers.Dense(units, activation='gelu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(dropout_rate)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention) # Add & Norm\n",
    "\n",
    "    # Model ìƒì„± ì‹œ name ì „ë‹¬\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfad02e",
   "metadata": {},
   "source": [
    "## Step 5. To define GPT model \n",
    "1. í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜ í›„ ì„ë² ë”©\n",
    "2. ë‹¨ì–´ ìœ„ì¹˜ ì •ë³´ë¥¼ í•™ìŠµ ê°€ëŠ¥í•œ ë²¡í„°ë¡œ ë³€í™˜\n",
    "3. ë‹¨ì–´ì˜ë¯¸ + ìœ„ì¹˜ì •ë³´ë¥¼ ë”í•˜ì—¬ ìµœì¢… ì…ë ¥ ë²¡í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c39ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. GPT ëª¨ë¸ ì •ì˜ ìˆ˜ì • (decoder_layer í˜¸ì¶œ ì‹œ ê³ ìœ  ì´ë¦„ ì „ë‹¬)\n",
    "def gpt(vocab_size, num_layers, units, d_model, num_heads, dropout_rate, maximum_position_encoding):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(inputs)\n",
    "\n",
    "    token_embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs) #Word Embedding\n",
    "\n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    positions = tf.range(start=0, limit=seq_len, delta=1) #Position Embedding\n",
    "    position_embeddings = tf.keras.layers.Embedding(maximum_position_encoding, d_model)(positions) #Position Embedding\n",
    "    position_embeddings = tf.expand_dims(position_embeddings, 0) #Position Embedding\n",
    "                                                                \n",
    "\n",
    "    embeddings = token_embeddings + position_embeddings #Word Embedding + Position Embedding\n",
    "    embeddings = tf.keras.layers.Dropout(dropout_rate)(embeddings)\n",
    "\n",
    "    x = embeddings\n",
    "    for i in range(num_layers):\n",
    "        # decoder_layer í˜¸ì¶œ ì‹œ ê³ ìœ í•œ ì´ë¦„(f\"decoder_layer_{i}\") ì „ë‹¬\n",
    "        x = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout_rate=dropout_rate,\n",
    "            name=f\"decoder_layer_{i}\" # ê³ ìœ  ì´ë¦„ ì „ë‹¬\n",
    "        )([x, look_ahead_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(vocab_size, name='outputs')(x)\n",
    "\n",
    "    # Model ìƒì„± ì‹œ inputsì™€ outputsê°€ Tensorì—¬ì•¼ í•¨\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name='GPT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d417e24",
   "metadata": {},
   "source": [
    "## Step 6. Loss Functions and Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "277cb6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GPT\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.range_1 (TFOpLambda)         (None,)              0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 256)          10240       tf.range_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 256)    2091520     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_1 (TFOpLambda)   (1, None, 256)       0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, None, 256)    0           embedding_2[0][0]                \n",
      "                                                                 tf.expand_dims_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 256)    0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_0 (Functional)    (None, None, 256)    527104      dropout_5[0][0]                  \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_layer_1 (Functional)    (None, None, 256)    527104      decoder_layer_0[0][0]            \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8170)   2099690     decoder_layer_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 5,255,658\n",
      "Trainable params: 5,255,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 6. Loss Functions and Model Compile (ìˆ˜ì • ì—†ìŒ - ë‹¨, ëª¨ë¸ ìƒì„± ì‹œ íŒŒë¼ë¯¸í„° í™•ì¸)\n",
    "\n",
    "# CustomSchedule, loss_function, accuracy í•¨ìˆ˜ëŠ” ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    # ... (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32) # stepì„ float32ë¡œ ë³€í™˜\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    # y_true shape: (batch_size, seq_len - 1)\n",
    "    # y_pred shape: (batch_size, seq_len - 1, vocab_size)\n",
    "    # íŒ¨ë”©ëœ ë¶€ë¶„(0)ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•œ ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), tf.float32)\n",
    "\n",
    "    # SparseCategoricalCrossentropy ì‚¬ìš© (from_logits=True)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    # ë§ˆìŠ¤í¬ ì ìš©\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    # ë°°ì¹˜ ë‚´ í‰ê·  ì†ì‹¤ ê³„ì‚° (ë§ˆìŠ¤í¬ëœ ë¶€ë¶„ ì œì™¸í•˜ê³  í‰ê· )\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "    # return tf.reduce_mean(loss) # ê¸°ì¡´ ë°©ì‹: íŒ¨ë”© ê³ ë ¤ ì•ˆ ëœ í‰ê· ì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # y_true shape: (batch_size, seq_len - 1)\n",
    "    # y_pred shape: (batch_size, seq_len - 1, vocab_size)\n",
    "    # ê°€ì¥ í™•ë¥  ë†’ì€ í† í° ì˜ˆì¸¡\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "\n",
    "    # ì˜ˆì¸¡ê³¼ ì‹¤ì œê°’ì´ ê°™ì€ì§€ í™•ì¸\n",
    "    match = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
    "\n",
    "    # íŒ¨ë”© ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), tf.float32)\n",
    "\n",
    "    # ë§ˆìŠ¤í¬ ì ìš©\n",
    "    match = tf.multiply(match, mask)\n",
    "\n",
    "    # ì •í™•ë„ ê³„ì‚° (ë§ˆìŠ¤í¬ëœ ë¶€ë¶„ ì œì™¸í•˜ê³  í‰ê· )\n",
    "    return tf.reduce_sum(match) / tf.reduce_sum(mask)\n",
    "    # return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred) # ê¸°ì¡´ ë°©ì‹: íŒ¨ë”© ê³ ë ¤ ì•ˆ ëœ ì •í™•ë„\n",
    "\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° (GPT-1 ë…¼ë¬¸ê³¼ ë‹¤ë¦„, ì‹¤í—˜ìš©ìœ¼ë¡œ ì‘ì€ ê°’ ìœ ì§€)\n",
    "NUM_LAYERS = 2 \n",
    "D_MODEL = 256  \n",
    "NUM_HEADS = 8  \n",
    "UNITS = 512    \n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "# maximum_position_encodingì€ íŒ¨ë”© í¬í•¨ ìµœëŒ€ ê¸¸ì´ MAX_LENGTH ì‚¬ìš©\n",
    "model = gpt(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    maximum_position_encoding=MAX_LENGTH) # Positional Encoding ìµœëŒ€ ê¸¸ì´\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ë° ì»´íŒŒì¼ (Learning Rate Scheduleì€ Transformer ë…¼ë¬¸ ë°©ì‹ ìœ ì§€)\n",
    "# GPT-1 ë…¼ë¬¸ì€ cosine schedule ì‚¬ìš© [cite: 96]\n",
    "learning_rate = CustomSchedule(d_model=D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "# ëª¨ë¸ ìš”ì•½ ì¶œë ¥ (í‰ê°€ ê¸°ì¤€ 9)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290486eb",
   "metadata": {},
   "source": [
    "## Step 7. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c43f8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Start Training for 20 epochs ---\n",
      "Epoch 1/20\n",
      "185/185 [==============================] - 10s 35ms/step - loss: 8.6161 - accuracy: 0.0992\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 6s 35ms/step - loss: 7.3494 - accuracy: 0.1543\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 6s 35ms/step - loss: 6.6402 - accuracy: 0.1610\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 7s 35ms/step - loss: 6.2858 - accuracy: 0.1746\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 7s 35ms/step - loss: 5.9959 - accuracy: 0.1931\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 5.6992 - accuracy: 0.2100\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 5.3880 - accuracy: 0.2279\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 5.0568 - accuracy: 0.2524\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 4.7081 - accuracy: 0.2817\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 4.3464 - accuracy: 0.3152\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 3.9819 - accuracy: 0.3485\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 3.6295 - accuracy: 0.3860\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 3.3027 - accuracy: 0.4213\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 7s 35ms/step - loss: 3.0019 - accuracy: 0.4628\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 7s 35ms/step - loss: 2.7441 - accuracy: 0.5011\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 2.5347 - accuracy: 0.5414\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 2.3705 - accuracy: 0.5748\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 2.2468 - accuracy: 0.6017\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 7s 36ms/step - loss: 2.1722 - accuracy: 0.6177\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 7s 35ms/step - loss: 2.1202 - accuracy: 0.6307\n",
      "\n",
      "Total training time for 20 epochs: 135.20 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 7. Training ---\n",
    "EPOCHS = 20 #  epoch 20ë²ˆ ì‹¤í–‰ í•˜ê¸°\n",
    "print(f\"\\n--- Start Training for {EPOCHS} epochs ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(dataset, epochs=EPOCHS)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nTotal training time for {EPOCHS} epochs: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
    "if history and history.history:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"í•™ìŠµ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd72841",
   "metadata": {},
   "source": [
    "## Step 8. To Predict What's Coming on the Next? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98fbd8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction Test ---\n",
      "\n",
      "--- Predicting for: 'ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ' ---\n",
      "1. Tokenized input: [8168, 76, 1264, 376]\n",
      "2. Padded input shape: (1, 39)\n",
      "3. Prediction output shape: (1, 39, 8170)\n",
      "4. Last real token index: 3\n",
      "   Logits shape for last token: (8170,)\n",
      "5. Predicted token ID (argmax): 2\n",
      "   Top 5 predictions:\n",
      "     - Rank 1: ID=2, Prob=0.9798, Token=' ?'\n",
      "     - Rank 2: ID=8169, Prob=0.0197, Token='<END>'\n",
      "     - Rank 3: ID=174, Prob=0.0002, Token='ì„œ'\n",
      "     - Rank 4: ID=342, Prob=0.0001, Token='ë§Œ'\n",
      "     - Rank 5: ID=1056, Prob=0.0000, Token='ê°€ì§€'\n",
      "6. Decoded token (argmax result): ' ?'\n",
      "  -> ìµœì¢… ì˜ˆì¸¡ ë‹¤ìŒ ë‹¨ì–´: ' ?' (ID: 2)\n",
      "\n",
      "--- Predicting for: 'ì˜í™” ì¶”ì²œí•´ì¤˜' ---\n",
      "1. Tokenized input: [8168, 953, 3900]\n",
      "2. Padded input shape: (1, 39)\n",
      "3. Prediction output shape: (1, 39, 8170)\n",
      "4. Last real token index: 2\n",
      "   Logits shape for last token: (8170,)\n",
      "5. Predicted token ID (argmax): 8169\n",
      "   Top 5 predictions:\n",
      "     - Rank 1: ID=8169, Prob=0.9361, Token='<END>'\n",
      "     - Rank 2: ID=1, Prob=0.0593, Token=' .'\n",
      "     - Rank 3: ID=205, Prob=0.0011, Token='ì—¬'\n",
      "     - Rank 4: ID=12, Prob=0.0009, Token=' . '\n",
      "     - Rank 5: ID=52, Prob=0.0008, Token='ì„œ '\n",
      "6. Decoded token (argmax result): '<END>'\n",
      "  -> ìµœì¢… ì˜ˆì¸¡ ë‹¤ìŒ ë‹¨ì–´: '<END>' (ID: 8169)\n",
      "\n",
      "--- Predicting for: 'ë°°ê³ íŒŒ' ---\n",
      "1. Tokenized input: [8168, 2312]\n",
      "2. Padded input shape: (1, 39)\n",
      "3. Prediction output shape: (1, 39, 8170)\n",
      "4. Last real token index: 1\n",
      "   Logits shape for last token: (8170,)\n",
      "5. Predicted token ID (argmax): 8169\n",
      "   Top 5 predictions:\n",
      "     - Rank 1: ID=8169, Prob=0.5525, Token='<END>'\n",
      "     - Rank 2: ID=52, Prob=0.3311, Token='ì„œ '\n",
      "     - Rank 3: ID=27, Prob=0.0276, Token='ê°€ '\n",
      "     - Rank 4: ID=7944, Prob=0.0272, Token=' '\n",
      "     - Rank 5: ID=15, Prob=0.0111, Token='ë„ '\n",
      "6. Decoded token (argmax result): '<END>'\n",
      "  -> ìµœì¢… ì˜ˆì¸¡ ë‹¤ìŒ ë‹¨ì–´: '<END>' (ID: 8169)\n",
      "\n",
      "--- Predicting for: 'ì•ˆë…•' ---\n",
      "1. Tokenized input: [8168, 906]\n",
      "2. Padded input shape: (1, 39)\n",
      "3. Prediction output shape: (1, 39, 8170)\n",
      "4. Last real token index: 1\n",
      "   Logits shape for last token: (8170,)\n",
      "5. Predicted token ID (argmax): 171\n",
      "   Top 5 predictions:\n",
      "     - Rank 1: ID=171, Prob=0.2494, Token='í•˜'\n",
      "     - Rank 2: ID=906, Prob=0.1599, Token='ì•ˆë…•'\n",
      "     - Rank 3: ID=13, Prob=0.1517, Token='ì„ '\n",
      "     - Rank 4: ID=174, Prob=0.0155, Token='ì„œ'\n",
      "     - Rank 5: ID=112, Prob=0.0147, Token='ì§„ì§œ '\n",
      "6. Decoded token (argmax result): 'í•˜'\n",
      "  -> ìµœì¢… ì˜ˆì¸¡ ë‹¤ìŒ ë‹¨ì–´: 'í•˜' (ID: 171)\n",
      "\n",
      "--- ì½”ë“œ ì‹¤í–‰ ì™„ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "# --- Step 8. Prediction\n",
    "def predict_next_token(sentence):\n",
    "    print(f\"\\n--- Predicting for: '{sentence}' ---\")\n",
    "    if not sentence: return \"ì…ë ¥ ë¬¸ì¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\", -1\n",
    "\n",
    "    # 1. ì „ì²˜ë¦¬ ë° í† í°í™”\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    tokenized_sentence = START_TOKEN + tokenizer.encode(sentence)\n",
    "    print(f\"1. Tokenized input: {tokenized_sentence}\")\n",
    "\n",
    "    # ì…ë ¥ ê¸¸ì´ ì œí•œ\n",
    "    if len(tokenized_sentence) >= MAX_LENGTH:\n",
    "         tokenized_sentence = tokenized_sentence[:MAX_LENGTH-1]\n",
    "         print(f\"   (Input truncated to {len(tokenized_sentence)} tokens)\")\n",
    "\n",
    "    # 2. ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜ ë° íŒ¨ë”©\n",
    "    encoder_input = tf.expand_dims(tokenized_sentence, 0)\n",
    "    padded_input = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        encoder_input, maxlen=MAX_LENGTH - 1, padding='post'\n",
    "    )\n",
    "    print(f\"2. Padded input shape: {padded_input.shape}\")\n",
    "\n",
    "    # 3. ëª¨ë¸ ì˜ˆì¸¡\n",
    "    try:\n",
    "        predictions = model(padded_input, training=False)\n",
    "        print(f\"3. Prediction output shape: {predictions.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Model prediction failed: {e}\")\n",
    "        return \"ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ\", -1\n",
    "\n",
    "    # 4. ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ë¡œì§“ ê°€ì ¸ì˜¤ê¸°\n",
    "    last_token_index = tf.shape(encoder_input)[1].numpy() - 1\n",
    "    if last_token_index < 0: last_token_index = 0\n",
    "    print(f\"4. Last real token index: {last_token_index}\")\n",
    "\n",
    "    pred_seq_len = tf.shape(predictions)[1]\n",
    "    if last_token_index >= pred_seq_len:\n",
    "        print(f\"   Warning: last_token_index ({last_token_index}) >= pred_seq_len ({pred_seq_len}). Adjusting index.\")\n",
    "        last_token_index = pred_seq_len - 1\n",
    "\n",
    "    last_token_logits = predictions[0, last_token_index, :]\n",
    "    print(f\"   Logits shape for last token: {last_token_logits.shape}\")\n",
    "\n",
    "    # 5. ê°€ì¥ í™•ë¥  ë†’ì€ í† í° ID ì°¾ê¸° + Top 5 í™•ì¸\n",
    "    predicted_token_id = tf.argmax(last_token_logits).numpy()\n",
    "    print(f\"5. Predicted token ID (argmax): {predicted_token_id}\")\n",
    "\n",
    "    probabilities = tf.nn.softmax(last_token_logits).numpy()\n",
    "    top_k_indices = np.argsort(probabilities)[-5:][::-1]\n",
    "    top_k_probs = probabilities[top_k_indices]\n",
    "\n",
    "    print(\"   Top 5 predictions:\")\n",
    "    for i in range(len(top_k_indices)):\n",
    "        current_id = top_k_indices[i]\n",
    "        # START_TOKEN ë˜ëŠ” END_TOKEN IDì¸ì§€ í™•ì¸ í›„ ë””ì½”ë”©\n",
    "        if current_id == START_TOKEN[0]:\n",
    "            token_word = \"<START>\"\n",
    "        elif current_id == END_TOKEN[0]:\n",
    "            token_word = \"<END>\"\n",
    "        elif current_id < tokenizer.vocab_size: # ìœ íš¨í•œ ë²”ìœ„ ë‚´ IDë§Œ decode í˜¸ì¶œ\n",
    "             try:\n",
    "                 token_word = tokenizer.decode([current_id])\n",
    "             except ValueError:\n",
    "                 token_word = \"<DECODE_ERROR>\" # í˜¹ì‹œ ëª¨ë¥¼ ë‹¤ë¥¸ decode ì˜¤ë¥˜ ëŒ€ë¹„\n",
    "        else:\n",
    "            token_word = \"<INVALID_ID>\" # ë²”ìœ„ ë°– ID ì²˜ë¦¬\n",
    "\n",
    "        print(f\"     - Rank {i+1}: ID={current_id}, Prob={top_k_probs[i]:.4f}, Token='{token_word}'\")\n",
    "\n",
    "    # 6. ìµœì¢… ì˜ˆì¸¡ëœ í† í° ID -> ë‹¨ì–´ ë³€í™˜ (Special Token ì²˜ë¦¬ í¬í•¨)\n",
    "    if predicted_token_id == START_TOKEN[0]:\n",
    "        predicted_token = \"<START>\"\n",
    "    elif predicted_token_id == END_TOKEN[0]:\n",
    "        predicted_token = \"<END>\"\n",
    "    elif predicted_token_id < tokenizer.vocab_size:\n",
    "        try:\n",
    "            predicted_token = tokenizer.decode([predicted_token_id])\n",
    "        except ValueError:\n",
    "             predicted_token = \"<DECODE_ERROR>\"\n",
    "    else:\n",
    "         predicted_token = \"<INVALID_ID>\"\n",
    "\n",
    "    print(f\"6. Decoded token (argmax result): '{predicted_token}'\")\n",
    "\n",
    "    return predicted_token, int(predicted_token_id) # IDëŠ” ì •ìˆ˜í˜•ìœ¼ë¡œ ë°˜í™˜\n",
    "\n",
    "# ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "print(\"\\n--- Prediction Test ---\")\n",
    "test_sentences = [\"ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ\", \"ì˜í™” ì¶”ì²œí•´ì¤˜\", \"ë°°ê³ íŒŒ\", \"ì•ˆë…•\"]\n",
    "for sent in test_sentences:\n",
    "    pred_word, pred_id = predict_next_token(sent)\n",
    "    print(f\"  -> ìµœì¢… ì˜ˆì¸¡ ë‹¤ìŒ ë‹¨ì–´: '{pred_word}' (ID: {pred_id})\")\n",
    "\n",
    "print(\"\\n--- ì½”ë“œ ì‹¤í–‰ ì™„ë£Œ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a995f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
